{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAPIKEY = 'sk-proj-hOmuRvsoxS0OPbv3sQaHT3BlbkFJLexvP8eGlwIVOwOf1ZWu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_link(link=None,query=None):\n",
    "\n",
    "  if(link):\n",
    "    try:\n",
    "      loader = WebBaseLoader(web_path=(link,), bs_kwargs=dict(parse_only = bs4.SoupStrainer(\n",
    "        class_ = (\"post-header\", \"post-content\")\n",
    "      )))\n",
    "\n",
    "      webpagedoc = loader.load()\n",
    "\n",
    "      text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "\n",
    "      global documents\n",
    "      documents = text_splitter.split_documents(webpagedoc)\n",
    "\n",
    "      #vector embedding and storage\n",
    "      global db\n",
    "      db = \"DB\"\n",
    "\n",
    "      db = Chroma.from_documents(documents[:15], OpenAIEmbeddings(openai_api_key = OPENAPIKEY))\n",
    "\n",
    "      return \"Link Read\"\n",
    "\n",
    "    except Exception as e:\n",
    "      return str(e)\n",
    "\n",
    "  else:\n",
    "      result = \"No Data\"\n",
    "\n",
    "      if(result==\"No Data\"):\n",
    "        result = db.similarity_search(query)\n",
    "        result = result[0].page_content\n",
    "        pass\n",
    "\n",
    "      return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_file(path, message):\n",
    "  #implement pdf query logic here\n",
    "\n",
    "  loader = PyPDFLoader(path)\n",
    "  docs = loader.load()\n",
    "\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "  documents = text_splitter.split_documents(docs)\n",
    "    \n",
    "  db = Chroma.from_documents(documents, OpenAIEmbeddings(openai_api_key=OPENAPIKEY))\n",
    "  query = message\n",
    "  results = db.similarity_search(query, k=5)  # Retrieve top 5 relevant chunks\n",
    "    \n",
    "    # Aggregate the search results into a single response\n",
    "  response_chunks = [result.page_content for result in results]\n",
    "  response = \"\\n\\n\".join(response_chunks)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_file(path, message):\n",
    "  #implement text query logic here\n",
    "\n",
    "  loader = TextLoader(path)\n",
    "  text_documents = loader.load()\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "  documents = text_splitter.split_documents(text_documents)\n",
    "\n",
    "  db = Chroma.from_documents(documents[:15], OpenAIEmbeddings(openai_api_key = OPENAPIKEY))\n",
    "\n",
    "  query = message\n",
    "  \n",
    "  result = db.similarity_search(query)\n",
    "\n",
    "  response = result[0].page_content\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[['What is the threat model?', 'they showed that a machine learning model has attacker-desired behaviors (e.g., makes incorrect predictions for indiscriminate\\ntesting inputs, predicts attacker-chosen target labels for attacker-chosen testing inputs) when trained on the poisoned training\\ndataset. Different from existing studies [ 35,64,65,69], our attacks do not poison the training dataset of a LLM. Instead, our\\nattacks poison the knowledge database used to augment a LLM such that the LLM generates attacker-chosen target answers for\\nattacker-chosen questions.\\n3 Problem Formulation\\n3.1 Threat Model\\nWe characterize the threat model with respect to the attacker’s goals, background knowledge, and capabilities.\\nAttacker’s goals: Suppose an attacker selects an arbitrary set of Mquestions (called target questions ), denoted as Q1,Q2,···,QM.\\nFor every target question Qi, the attacker could select an arbitrary attacker-desired answer Ri(called target answer ) for it. For\\n\\nThere is also a branch of work on attacking LLMs to extract pre-training data, private knowledge (Carlini et al, 2020) or attacking model training process via data poisoning (Carlini et al. 2023). We would not cover those topics in this post.\\nBasics#\\nThreat Model#\\nAdversarial attacks are inputs that trigger the model to output something undesired. Much early literature focused on classification tasks, while recent effort starts to investigate more into outputs of generative models. In the context of large language models In this post we assume the attacks only happen at inference time, meaning that model weights are fixed.\\n\\nText Generation#\\nGiven an input $\\\\mathbf{x}$ and a generative model $p(.)$, we have the model output a sample $\\\\mathbf{y} \\\\sim p(.\\\\vert\\\\mathbf{x})$ . An adversarial attack would identify such $p(\\\\mathbf{x})$ that $\\\\mathbf{y}$ would violate the built-in safe behavior of the model $p$; E.g. output unsafe content on illegal topics, leak private information or model training data. For generative tasks, it is not easy to judge the success of an attack, which demands a super high-quality classifier to judge whether $\\\\mathbf{y}$ is unsafe or human review.\\nWhite-box vs Black-box#\\nWhite-box attacks assume that attackers have full access to the model weights, architecture and training pipeline, such that attackers can obtain gradient signals. We don’t assume attackers have access to the full training data. This is only possible for open-sourced models.\\n\\nAttack\\nType\\nDescription\\n\\n\\n\\n\\nToken manipulation\\nBlack-box\\nAlter a small fraction of tokens in the text input such that it triggers model failure but still remain its original semantic meanings.\\n\\n\\nGradient based attack\\nWhite-box\\nRely on gradient signals to learn an effective attack.\\n\\n\\nJailbreak prompting\\nBlack-box\\nOften heuristic based prompting to “jailbreak” built-in model safety.\\n\\n\\nHuman red-teaming\\nBlack-box\\nHuman attacks the model, with or without assist from other models.\\n\\n\\nModel red-teaming\\nBlack-box\\nModel attacks the model, where the attacker model can be fine-tuned.\\n\\nFig. 1. An overview of threats to LLM-based applications. (Image source: Greshake et al. 2023)\\nClassification#\\nAdversarial attacks on classifiers have attracted more attention in the research community in the past, many in the image domain. LLMs can be used for classification too. Given an input $\\\\mathbf{x}$ and a classifier $f(.)$, we would like to find an adversarial version of the input, denoted as $\\\\mathbf{x}_\\\\text{adv}$, with imperceptible difference from $\\\\mathbf{x}$, such that $f(\\\\mathbf{x}) \\\\neq f(\\\\mathbf{x}_\\\\text{adv})$.\\nText Generation#']]\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### GLOBAL VARIABLES ####################################\n",
    "user_mode = None\n",
    "path_file = None    #path to the current file uploaded\n",
    "\n",
    "############################## FUNCTIONS ########################################\n",
    "def echo(message, history):\n",
    "    #message holds the input query from the user\n",
    "    #history holds the chat history in the form of a list containing lists.\n",
    "    #The inner list structure: [{User text},{Bot text}]\n",
    "\n",
    "    print(history)\n",
    "\n",
    "    #No mode\n",
    "    if(user_mode==None):\n",
    "      return \"Please select an option\"\n",
    "\n",
    "    #web link\n",
    "    if(user_mode==3):\n",
    "      url_pattern = re.compile(r'https?://\\S+')\n",
    "\n",
    "      # Search for a URL in the message text\n",
    "      matchCon = url_pattern.search(message)\n",
    "\n",
    "      if matchCon:\n",
    "          url = matchCon.group(0)  # Extract the matched URL\n",
    "          response = web_link(link=url)\n",
    "      else:\n",
    "          #function to give query to appropriate web link function and return response from it\n",
    "          response = web_link(query=message)\n",
    "\n",
    "      return response\n",
    "\n",
    "    #text file mode\n",
    "    if(user_mode==2):\n",
    "      return text_file(path_file, message) #path to current .txt file uploaded for this mode\n",
    "\n",
    "    #pdf file mode\n",
    "    if(user_mode==1):\n",
    "      return pdf_file(path_file, message)  #path to current .pdf file uploaded for this mode\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "def process_files(argument):\n",
    "\n",
    "    global path_file\n",
    "    path_file = argument\n",
    "\n",
    "    return gr.File(label=\"Upload File\", visible=True,interactive=True)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "def change_mode(choice):\n",
    "    global user_mode\n",
    "\n",
    "    if choice == \"Web Link\":\n",
    "        user_mode = 3\n",
    "        return gr.File(visible=False), gr.Button(\"Submit\", visible=False), gr.Button(\"Cancel\", visible=False)\n",
    "    elif choice == \"Text File\":\n",
    "        user_mode = 2\n",
    "        return gr.File(label=\"Upload File\",visible=True), gr.Button(\"Submit\", visible=True), gr.Button(\"Cancel\", visible=True)\n",
    "    else:\n",
    "        user_mode = 1\n",
    "        return gr.File(label=\"Upload File\",visible=True), gr.Button(\"Submit\", visible=True), gr.Button(\"Cancel\", visible=True)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------#\n",
    "\n",
    "def cancel_upload():\n",
    "    return gr.File(label=\"Upload File\", visible=True,interactive=True)\n",
    "\n",
    "############################## INTERFACE CODE ###################################\n",
    "with gr.Blocks() as demo:\n",
    "    #set up radio element and file input\n",
    "    with gr.Row():\n",
    "      radio = gr.Radio(\n",
    "          [\"PDF File\", \"Text File\", \"Web Link\"], label=\"Select Mode\"\n",
    "      )\n",
    "\n",
    "      # input = gr.Interface(process_files,inputs='files',outputs=None)\n",
    "      with gr.Column():\n",
    "        file_input = gr.File(label=\"Upload File\", visible=False,interactive=True)\n",
    "\n",
    "        #set up buttons\n",
    "        with gr.Row():\n",
    "            submit_btn = gr.Button(\"Submit\", visible=False)\n",
    "            cancel_btn = gr.Button(\"Cancel\", visible=False)\n",
    "\n",
    "\n",
    "    #add radio element event listener\n",
    "    radio.change(fn=change_mode, inputs=radio, outputs=[file_input,submit_btn,cancel_btn])\n",
    "\n",
    "    # Set up submit button to process files\n",
    "    submit_btn.click(fn=process_files, inputs=[file_input], outputs=[file_input])\n",
    "\n",
    "    # Set up cancel button to clear file input\n",
    "    cancel_btn.click(fn=cancel_upload, inputs=None, outputs=file_input)\n",
    "\n",
    "    #set up Chat Interface\n",
    "    gr.ChatInterface(\n",
    "        fn=echo,\n",
    "        title=\"Doc Bot\",\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
